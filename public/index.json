[{"categories":["comp-sci"],"contents":"Project Euler is a series of increasingly difficult Mathematical questions/puzzles that tends to scratch the problem solving itch that many programmer are afflicted with. While they can usually be brute forced via computer programs usually they have an elegant solution that can be worked out with just a pencil and paper. As such at least for programmers it really is up to the individual how much deep thought versus straight coding they want to do, which, I think makes for a pretty good learning curve. When you cant figure out the elegant solution, you can usually find a brute force way through it; When you cant brute force it, you have to sit back, think and usually you can come up with an elegant efficient way to solve the problem. This is pretty similar to the real life challenges in programming really get resolved, first try to come up with a \u0026lsquo;good\u0026rsquo; way to do things, if not then just resolve it by brute force, finally when necessary put in deep thought and or research to really find an efficient solution.\nSo with that being said, going to look at Euler Problem #1:\n If we list all the natural numbers below 10 that are multiples of 3 or 5, we get 3, 5, 6 and 9. The sum of these multiples is 23. Find the sum of all the multiples of 3 or 5 below 1000.\n I remember in fifth grade, my math teacher showed us a very small Basic program (no clue which specific Basic, but it ran on MS-DOS so\u0026hellip;) that would count up to 1 million and print the numbers to the screen. The most awe inspiring part of the lesson was not the program, but the fact that he had to leave the program running until the next day in order for it to complete. Really impressed upon us not only the power of computer programs, but also the shear immensity of the number 1 million. Big ups to Mr Weinstein. I tried to recreate the experience for my son a few years ago, but alas the program finished REALLY quickly. I guess that comes down to Moore\u0026rsquo;s law spoiling the awesomeness of the number 1,000,000, let alone 1000.\nSo in honor of these realities, and because I also want to look at some basic performance comparisons across languages, and in celebration of the inventors of the most powerful and important computing system in the history of the earth lets bump that 1000 up to 10,000,000 (a crore). An before anyone questions wether Hindu-Arabic is arguably the most important computing system invented by humankind, quick tell me what is MCMLXXXVII divided by XVIII? I\u0026rsquo;ll wait, might take a couple hours for you to work out if you dont convert to a place value based system with a representation of zero that allows finite mechanical application of a small set of basic rules to resolve long division. Long division doesn\u0026rsquo;t just fall out of all number systems. This number system is what made calculation, beyond hands and toes possible for the vast majority of society. So for the shear democratization of arithmetic and advancement of mathematics both practical and academic that this system allowed, I think it easily ranks as number 1 computing system in human history. But I digress\u0026hellip;\nLet\u0026rsquo;s get down the summing up all the multiples of 3 or 5 below 10,000,000.\nPowerShell $max = 10000000 - 1 $sum = 0 1..$max | ? { (( $_ % 3 ) -eq 0) -or (($_ % 5) -eq 0) } | % { $sum += $_ } $sum Kind of painful to read, and this is not even the most compressed way to write this in PowerShell. I actually added line breaks and broke out the sum variable to make it a little easier to read. Being 100% fair, the syntax of powershell is optimized for quick input of \u0026lsquo;fire and forget\u0026rsquo; dispatches at the command line. Every ugly weird magically shortcut here, I wouldnt trade away from the language at all because of the speed at which you can crank out PowerShell one liners. But its still ugly and hard to read.\nI checked the performance with hyperfine. Why? Well programs execution is fairly nondeterministic. It can depend on a hundred different things, mostly commonly related to caching/optimizations that the program runtime has made, or contention for resources during execution. As such it is often necessary to let the code execute a bit to \u0026lsquo;warm up\u0026rsquo; and then also to actually execute a reasonable number of times to determine the average run time and variance. hyperfine does this kind of thing for you, without having to do any special coding on your part. The results looked like below:\n❯ hyperfine 'pwsh .\\powershell\\euler.ps1'\rBenchmark #1: pwsh .\\powershell\\euler.ps1 0\rTime (mean ± σ): 135.411 s ± 3.449 s [User: 0.0 ms, System: 5.1 ms] 0\rRange (min … max): 131.319 s … 142.754 s 10 runs\rWhich is pretty significantly slow run on modern hardware clock in at over 2 minutes. I wasnt able to find incredible detail on how PowerShell actually executes, but at a minimum I know there is an interpreter that does a LOT of dynamic indirection related to PSObject and PSCustomObject, and then calls down to .Net code that has to be compiled down (I am assuming) to Microsoft Intermediate Language, and then on execution that MSIL has to be JIT\u0026rsquo;ed (Just In Time converted) to native machine code. It seems at least niavely that this has to be on a line by line basis to enable PowerShell to function as a shell. As such I wasnt surprised it was slow but how slow is slow?\nI was curious to see how another \u0026lsquo;slow\u0026rsquo; interpreted language peformed:\nPython max = 10000000 sum = 0 for i in range(1, max): if i%3==0 or i%5==0: sum += i print(str(sum)) Wow so much more readable, I think perhaps a complete non programmer could look at this and have a decent idea of what is going on, only real headscratchers would be the % modulus functions, the == and += symbol.\n❯ hyperfine 'python .\\python\\euler.py'\rBenchmark #1: python .\\python\\euler.py 0\rTime (mean ± σ): 1.100 s ± 0.036 s [User: 2.9 ms, System: 6.2 ms] 0\rRange (min … max): 1.065 s … 1.147 s 10 runs\rWhats widely regarded as the slowest mainstream programming language is over 100 times faster on this microbenchmark. Even in the realm of popular interpreted dynamic languages such as JavaScript, Lua, Perl, Python is considered dog slow. And lets be crystal clear here:\n Microbenchmarks mean nothing to anything except the very specific exact lines of code in question\n But still 2 orders of magnitude faster, on very simple looping and integer arithmetic.\nThat got me much more curious, what about a decently performant programming language? C# is a relatively performant statically typed compiled language that executes on a virtual machine with a garbage collector.\nC# using System; namespace euler_dotnet { class Program { static void Main(string[] args) { int max = 10000000; Int64 sum = 0; for(int i=0; i \u0026lt; max; i++) { if(((i % 3)==0)||((i % 5)==0)) { sum += i; } } Console.WriteLine(sum.ToString()); } } } First thing we are going to notice looking at the code is how verbose it is, probably 50% of the code is just boilerplate that really has nothing to do with the actually problem we are trying to solve. It is an extremely explict language, thats for sure. Lets see how it performs though.\n❯ dotnet build --configuration Release .\\dotnet\\\r❯ hyperfine 'python '.\\dotnet\\bin\\Release\\netcoreapp3.1\\euler.exe'\rBenchmark #2: .\\dotnet\\bin\\Release\\netcoreapp3.1\\euler.exe\rTime (mean ± σ): 56.5 ms ± 0.6 ms [User: 0.9 ms, System: 2.9 ms] 0\rRange (min … max): 55.9 ms … 59.6 ms 46 runs About 19 times faster than Python off rip. Maybe the trade off between verbosity and performance is worth it. If we are being REALLY fair we also should note the build step, thats the lines that go dotnet build etc. The build step does eat up time on its own. Especially in exploritory development the constant code, build, wait, execute cycle really does slow down development when you take into account a developer does this cycle hundreds of times a day. Both Python and PowerShell, just do the magic to make your code actually execute at runtime.\nI wanted to go one level deeper, and see how a language that compiles down to a single native executable that doesnt depend on a garbage collector. I chose Rust because, frankly last time I tried to teach my 16 year old son C, it blue screened my computer. So lets try the much safer low level language that has been stackoverflow\u0026rsquo;s Most Loved Programming Language for 3 years in a row.\nRust fn main() { let max = 10000000; let mut sum = 0i64; for i in 1..max { if i % 3 == 0 || i % 5 == 0 { sum += i; } } println!(\u0026#34;{}\u0026#34;,sum); } Before we even run it, stands out that it is pretty near to python in readability, sure there are semicolumns everywhere, and the weird 0i64 but\u0026hellip; not anywhere as ugly as PowerShell, nor as long winded as C#.\nHow does it run though?\n❯ cargo build --manifest-path .\\rust\\Cargo.toml --release\r❯ hyperfine '.\\rust\\target\\release\\euler.exe'\rBenchmark #1: .\\rust\\target\\release\\euler.exe 0\rTime (mean ± σ): 15.5 ms ± 0.2 ms [User: 1.0 ms, System: 3.8 ms] 0\rRange (min … max): 15.0 ms … 16.1 ms 143 runs\rSo about 3.6 times faster than C#, about 70 times faster than Python, and about 9,000 times faster than PowerShell. Thats pretty fast. Must be pretty much as fast as possible right?\nMath This series is tagged comp-sci for a reason, so in the next posts we are going to try to apply the Queen of the Sciences to help speed up this calculation for us.\nI leave off with the Gza Genius:\n At the height of their fame and glory, they turned on one another\nEach struggling in vain for ultimate supremacy\nIn the passion and depth of their struggle\nThe very art that had raised them to such Olympian heights was lost\n   ","permalink":"/blog/on-programming-language-performance/","tags":["Programming"],"title":"On Programming Language Performance"},{"categories":["square-biz"],"contents":"Hype or Automation? That\u0026rsquo;s a good question, as there seems to be a wide range of answers. However the basic idea behind HyperAutomation to envision your automation journey as travel upwards to higher levels of automation that build on the capabilities introduced in the previous levels.\n The ground floor starts with previous years\u0026rsquo; Gartner darling, Robotic Process Automation (RPA), which is essentially the application of small simple rule based programs which can automate repetative work. Now, imagine if you could apply RPA to all your low level business processes? Not only is the repetative work automated, but beyond that now every single process and/or transaction can also be captured as a digital event and the structured data associated with that event. These events could be analyzed by a digital \u0026lsquo;brain\u0026rsquo; that could then apply logic of arbitrary complexity and automatically trigger other business events without human intervention or with human approval if required. Rich workflows could be created to orchestrate complex interactions between dozens of disparate business processes via these events. On top of the previous layer of transactional automated business processing, Machine Learning algorithms can analyze the raw business event stream to generate new insights into what makes your business tick, and provide N-dimensional reporting and forecasting in realtime for human consumption. Furthermore this stream of digital events and the complex interactions between the constituent parts could be thought of as a Digital Twin that exactly maps to your real world business. Data Science can be used to analyze this Digital Twin, to unearth relationships between component business processes beyond human intuition. Modern Artificial Intelligence can apply a wide range of cutting edge optimiztion algorithms, run millions of simulations of what would happen to your real world business if a given change is made, select the best outcomes ranked along any chosen weighting criteria, and then provide recommendations for C-level executives along with the data to back it up.  Let me be clear this is not science fiction, this is not a pipe dream, this is not just hype and buzzword bingo. However this is also not new to 2020, in any shape, form, or fashion. This is the self same \u0026lsquo;digitial transformation\u0026rsquo; that has been chased for almost 2 decades at this point. The main difference between this year\u0026rsquo;s take on \u0026lsquo;digital transformation\u0026rsquo; and the previous years\u0026rsquo;, if there is one, is the idea that the transformation starts at the leaf nodes. It starts at the low level business processes being taken over by RPA. There is a certain compelling rationality to this.\nInstead of going for the incredibly complex migration to a new multi-multimillion dollar CRM or ERP platform, building out a risky (Micro)Service Oriented Architecture that might never actually see adoption across your enterprise even if successfully developed, or any of the other big bang top down approaches to digital transformation why not go at it from the opposite direction? Start with digitizing the dozens or even hundreds of simple processes that make up your business with RPA. Each individual automation of a single business process is a relatively small but concrete win that provides immediate real world bottomline value to the business. The best thing about this approach is you can afford to fail on a given automation attempt, still reap the benefits from your other successful automation attempts, get up, dust your knees off and try again. Once you have completed this leaf-node automation phase, proven your capability and aquired digital transformation competence, then take on the more complex components. Honestly this is just the proven industry standard iterative development philosophy writ large.\n  ","permalink":"/blog/hyperautomation/","tags":["Business"],"title":"HyperAutomation"},{"categories":["square-biz"],"contents":"Foundation of Execution On the startup side of the industry, the most commonly talked about business strategies revolve around Disruption. But, for my money no one has ever put it as eloquently as the young brooklyn kid who actually disrupted his field with brutal efficiency.\n Everybody has a plan until they get punched in the mouth - Mike Tyson\n On the other side of the software game, in the Enterprise, equally cliche is the oft stated strategy of Agility. I think the famous slightly sped up clip of a 19 year old Mike Tyson going through his paces during a training session makes the point better than any words ever could: Mike knows Agility too.\nNeither Disruption or Agility are strategies. Disruption is an outcome. Agility is a resource. A strategy is the focused forward looking plan followed with driving dedictation, and implementated with unrelenting discipline in persuit of a long term goal that enables even longer term goals.\nIn the case of Mike Tyson, the strategy was the regime of training, the endless cardio, the expert selection of the most efficient and powerful movements, the grinding repetition to encode these movements in muscle memory. This is how one aquires Agility.\nA lifetime of study of the fundamentals of the sweet science, the accurate assessment of opponents weakness, relentless destruction of ones own weaknesses resulting in impregnible defence, the absolute mastery of psychological warfare, and the relentless training necessary to build that world famous and world shattering power. That is how Disruption is actualized.\nUnderstanding what is and isn\u0026rsquo;t a strategy is probably the first step in actually implementing one. As with anything, the study of the history is the most likely the best way to predict the future. The seminal Strategy: A History maybe too much of a tome for casual reading, but in audio book format is an engaging and entertaining primer on the matter.\nFrom the perspective of the Enterprise and it\u0026rsquo;s love/hate relationship with Information Technology in particular, I keep going back to the fundamentals of Enterprise Architecture As Strategy: Creating a Foundation for Business Execution. This blog owes a lot of its fundations to the theories exposed by this book.\nStrategic Technology Trends for 2020  Through the lights, camera, action, glamour, glitter and gold, I unfold the scroll\n Enterprise Information Technology\u0026rsquo;s favorite problematic bae has released Gartner Top 10 Strategic Technology Trends for 2020. One cannot escape the logical incongruence of the term \u0026lsquo;strategy\u0026rsquo; being applied to the term \u0026lsquo;trend\u0026rsquo;, fundamentally if your IT strategy changes every 12 months you have no strategy. Also, opinion\u0026rsquo;s on Gartner vary, and vary, and vary. Regardless of what you feel about Gartner as a business entity, the reliability of their analysis, or their outsized impact on the hype cycle, they unequivocally are thought leaders that the majority of CIO\u0026rsquo;s turn to for guidance. Understanding the influences on those who control the purse strings is never a bad bet in any business related strategy, so in the next couple blog posts I am going to dive into what I think are the most interesting of Gartner\u0026rsquo;s top 10.\nRead more about\u0026hellip; HyperAutomation  Read more about\u0026hellip; Democratization In the best of times any real world competitive strategy has to take into account imperfect information, and 2020 in particular may be the blackest swan on record. As such, I am going to end this with a big red cherry on top with the best strategic advice on the block\u0026hellip;\n From the Womb to the Tomb, Presume the Unpredictable - Nasir Jones\n   ","permalink":"/blog/strategic-foci/","tags":["Business"],"title":"Strategic Foci"},{"categories":["square-biz"],"contents":"Enterprise Information Technology is about to get caught with it’s pants down.  The New Office looks a lot like the Old Office except you don’t get any points for ‘looking’ busy.\n There was a time when enterprise profit centers had no real choice but to rely on their internal information technology departments. Projects took 3 months just to clear to the hurdles of resource allocation and change management. That time was 2019.\nIn 2020, 58% of knowledge workers are now working remotely and that’s only the beginning of the sea change.\nFor the last 15 years the single biggest strategic decision point in corporate IT was ‘on shoring’ versus ‘off shoring’. In a world where the vast majority of knowledge workers are working remotely, there is no difference between ‘onshore’ and ‘offshore’. That’s an old mindset that just went the way of the dodo bird.\nTwo Words: Managed Services  There’s a war going on outside no man is safe from. You can run but you can’t hide forever.\n   The Dodo Bird, The Giant Ground Sloth, The Eastman Kodak Company. There is a certain kind of organism that manages to thrive in isolation, yet completely collapses in the face of competition and predation. The world is about to come to grips with the reality that the vast majority of enterprise information technology departments fall into this category.\nImagine a world where delivery matters. Where execution matters. Where profit centers contract directly with streamlined efficient providers whos only way to survive is their ability to deliver… on spec, on time, on budget.\nSurvival of the fit. Only the strong survive. ","permalink":"/blog/welcome-to-the-new-office/","tags":["Business"],"title":"Welcome to the New Office"}]